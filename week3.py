# -*- coding: utf-8 -*-
"""Week3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t0XzQkli29JlOiSaWhF8Ew7D82Q0sVO_
"""

import pandas as pd
from io import StringIO

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import sys
if sys.version_info[0] >= 3:
    unicode = str

csv_data='''A,B,C,D
1.0,2.0,3.0,4.0
5.0,6.0,,8.0
0.0,11.0,12.0,'''

csv_data=unicode(csv_data)
df=pd.read_csv(StringIO(csv_data))

df

df.isnull()

df.isnull().sum()

df.values

df.dropna()

df.dropna(axis=1)

from sklearn.impute import SimpleImputer
import numpy as np

imputer=SimpleImputer(missing_values=np.nan,strategy='mean')

imputer=imputer.fit(df)

imputed_data=imputer.transform(df.values)

imputed_data

#creating categorical dataset
import pandas as pd

df=pd.DataFrame([
  ['green','M',10.1,'class1'],
  ['red','L',13.5,'class2'],
  ['blue','XL',15.3,'class1']
])

df

df.columns

df.columns=['color','size','price','classlabel']
df

df.loc[3]=['violet','XXL',10.5,'class3']

df

size_mapping={'XXL':4,'XL':3,'L':2,'M':1}
df['size']=df['size'].map(size_mapping)
df

size_mapping.items()

inv_size_mapping={v:k for k,v in size_mapping.items()}
inv_size_mapping

df['size']=df['size'].map(inv_size_mapping)
df

#Noise smoothing
import pandas as pd
import numpy as np

n=200
df=pd.DataFrame(np.random.randint(0,100,size=(n,1)),columns=list('T'))
df

#equal width binning
import matplotlib.pyplot as plt
hist=plt.hist(df['T'],ec='violet')
plt.show()

print("Bins")
print(hist[1])

#scott
hist=plt.hist(np.array(df['T']),bins='scott',ec='violet')
plt.show()
print('Bins')
print(hist[1])

#fd
hist=plt.hist(np.array(df['T']),bins="fd",ec='violet')
plt.show()
print('Bins')
print(hist[1])

hist=plt.hist(np.array(df['T']),bins='rice',ec='violet')
plt.show()
print('Bins')
print(hist[1])

